{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00066f8f-78d3-409f-b084-5c4983b85eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f7d29fb8-6f8d-46bd-8d72-d87d7bdfc819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Intervention_descriptor</th>\n",
       "      <th>tax_increase</th>\n",
       "      <th>outlet_reduction</th>\n",
       "      <th>dec_smoking_prevalence</th>\n",
       "      <th>dec_tobacco_supply</th>\n",
       "      <th>dec_smoking_uptake</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>evidence_strength</th>\n",
       "      <th>qalys_pc</th>\n",
       "      <th>hs_costs_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combined tobacco endgame strategy (tobacco-fre...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0-14</td>\n",
       "      <td>Male</td>\n",
       "      <td>non-Māori</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.865526</td>\n",
       "      <td>-1284765.096725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Combined tobacco endgame strategy (tobacco-fre...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15-24</td>\n",
       "      <td>Male</td>\n",
       "      <td>non-Māori</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.708939</td>\n",
       "      <td>-1270055.987675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Combined tobacco endgame strategy (tobacco-fre...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25-44</td>\n",
       "      <td>Male</td>\n",
       "      <td>non-Māori</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.282615</td>\n",
       "      <td>-318700.524314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Combined tobacco endgame strategy (tobacco-fre...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45-64</td>\n",
       "      <td>Male</td>\n",
       "      <td>non-Māori</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.222291</td>\n",
       "      <td>-119003.652181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Combined tobacco endgame strategy (tobacco-fre...</td>\n",
       "      <td>10</td>\n",
       "      <td>90</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65+</td>\n",
       "      <td>Male</td>\n",
       "      <td>non-Māori</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.111505</td>\n",
       "      <td>-9656.694651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0                            Intervention_descriptor tax_increase  \\\n",
       "1  Combined tobacco endgame strategy (tobacco-fre...           10   \n",
       "2  Combined tobacco endgame strategy (tobacco-fre...           10   \n",
       "3  Combined tobacco endgame strategy (tobacco-fre...           10   \n",
       "4  Combined tobacco endgame strategy (tobacco-fre...           10   \n",
       "5  Combined tobacco endgame strategy (tobacco-fre...           10   \n",
       "\n",
       "0 outlet_reduction dec_smoking_prevalence dec_tobacco_supply  \\\n",
       "1               90                      7                  0   \n",
       "2               90                      7                  0   \n",
       "3               90                      7                  0   \n",
       "4               90                      1                  0   \n",
       "5               90                    0.5                  0   \n",
       "\n",
       "0 dec_smoking_uptake    age gender  ethnicity discount_rate evidence_strength  \\\n",
       "1                  0   0-14   Male  non-Māori             0               NaN   \n",
       "2                  0  15-24   Male  non-Māori             0               NaN   \n",
       "3                  0  25-44   Male  non-Māori             0               NaN   \n",
       "4                  0  45-64   Male  non-Māori             0               NaN   \n",
       "5                  0    65+   Male  non-Māori             0               NaN   \n",
       "\n",
       "0   qalys_pc     hs_costs_pc  \n",
       "1  40.865526 -1284765.096725  \n",
       "2  41.708939 -1270055.987675  \n",
       "3  13.282615  -318700.524314  \n",
       "4   7.222291  -119003.652181  \n",
       "5   1.111505    -9656.694651  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Excel file and save as DataFrame\n",
    "\n",
    "df = pd.read_excel('./Datasets/tobacco_data.xlsx')\n",
    "df.columns = df.iloc[0]\n",
    "df = df[1:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dc7372f5-136b-4d26-a5ff-1db7fcdc2794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax_increase</th>\n",
       "      <th>outlet_reduction</th>\n",
       "      <th>dec_smoking_prevalence</th>\n",
       "      <th>dec_tobacco_supply</th>\n",
       "      <th>dec_smoking_uptake</th>\n",
       "      <th>average_age</th>\n",
       "      <th>gender_idx</th>\n",
       "      <th>ethnicity_idx</th>\n",
       "      <th>qalys_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.865526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.708939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.282615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.222291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.111505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0  tax_increase  outlet_reduction  dec_smoking_prevalence  dec_tobacco_supply  \\\n",
       "1          10.0              90.0                     7.0                 0.0   \n",
       "2          10.0              90.0                     7.0                 0.0   \n",
       "3          10.0              90.0                     7.0                 0.0   \n",
       "4          10.0              90.0                     1.0                 0.0   \n",
       "5          10.0              90.0                     0.5                 0.0   \n",
       "\n",
       "0  dec_smoking_uptake  average_age  gender_idx  ethnicity_idx   qalys_pc  \n",
       "1                 0.0          7.0         0.0            1.0  40.865526  \n",
       "2                 0.0         20.0         0.0            1.0  41.708939  \n",
       "3                 0.0         33.0         0.0            1.0  13.282615  \n",
       "4                 0.0         55.0         0.0            1.0   7.222291  \n",
       "5                 0.0         75.0         0.0            1.0   1.111505  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform data\n",
    "\n",
    "# Map age group to integer\n",
    "avg_age_mapping = {\n",
    "    '0-14': 7,\n",
    "    '15-24': 20,\n",
    "    '25-44': 33,\n",
    "    '45-64': 55,\n",
    "    '65+': 75\n",
    "}\n",
    "\n",
    "# Map gender to integer\n",
    "gender_mapping = {\n",
    "    'Male': 0,\n",
    "    'Female': 1\n",
    "}\n",
    "\n",
    "# Map ethnicity to integer\n",
    "ethnicity_mapping = {\n",
    "    'Māori': 0,\n",
    "    'non-Māori': 1\n",
    "}\n",
    "\n",
    "# Apply the mapping to the 'Age_Group' column\n",
    "df['average_age'] = df['age'].map(avg_age_mapping)\n",
    "df['gender_idx'] = df['gender'].map(gender_mapping)\n",
    "df['ethnicity_idx'] = df['ethnicity'].map(ethnicity_mapping)\n",
    "\n",
    "# Impute missing values in 'average_age' with the mean\n",
    "df['average_age'] = df['average_age'].fillna(df['average_age'].mean())\n",
    "\n",
    "# Impute missing values in 'gender_idx' and 'ethnicity_idx' with the mode\n",
    "df['gender_idx'] = df['gender_idx'].fillna(df['gender_idx'].mode()[0])\n",
    "df['ethnicity_idx'] = df['ethnicity_idx'].fillna(df['ethnicity_idx'].mode()[0])\n",
    "\n",
    "# Convert the specified columns to floats\n",
    "df[['tax_increase', 'outlet_reduction', 'dec_smoking_prevalence', \n",
    "    'dec_tobacco_supply', 'dec_smoking_uptake', 'qalys_pc']] = df[['tax_increase', 'outlet_reduction', \n",
    "    'dec_smoking_prevalence', 'dec_tobacco_supply', 'dec_smoking_uptake', 'qalys_pc']].apply(pd.to_numeric, errors='coerce').astype('float')\n",
    "\n",
    "# Columns to be used for model building\n",
    "df_vape = df[['tax_increase', 'outlet_reduction', 'dec_smoking_prevalence', \n",
    "              'dec_tobacco_supply', 'dec_smoking_uptake', 'average_age', \n",
    "              'gender_idx', 'ethnicity_idx', 'qalys_pc']]\n",
    "\n",
    "# Display updated DataFrame\n",
    "df_vape.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56e74f74-8c71-4f40-9385-9e8613f87afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_pca(df):\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_vape)\n",
    "    \n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Check the explained variance ratio for the first two components\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    print(f\"Explained variance by component 1: {explained_variance[0]:.2f}\")\n",
    "    print(f\"Explained variance by component 2: {explained_variance[1]:.2f}\")\n",
    "    \n",
    "    # Create a scatter plot of the PCA results\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], c='blue', edgecolor='k', s=50)\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(f\"Principal Component 1 ({explained_variance[0]:.2f} variance)\")\n",
    "    plt.ylabel(f\"Principal Component 2 ({explained_variance[1]:.2f} variance)\")\n",
    "    plt.title(\"PCA of Dataset\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e151d8bf-4724-4dbb-90bf-c4f0bc356bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_vape[['tax_increase', 'outlet_reduction', 'dec_smoking_prevalence', \n",
    "              'dec_tobacco_supply', 'dec_smoking_uptake', 'average_age', \n",
    "              'gender_idx', 'ethnicity_idx']]\n",
    "y = df_vape[['qalys_pc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80aa077a-edb2-441d-aa46-85af9870d0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tax_increase</th>\n",
       "      <th>outlet_reduction</th>\n",
       "      <th>dec_smoking_prevalence</th>\n",
       "      <th>dec_tobacco_supply</th>\n",
       "      <th>dec_smoking_uptake</th>\n",
       "      <th>average_age</th>\n",
       "      <th>gender_idx</th>\n",
       "      <th>ethnicity_idx</th>\n",
       "      <th>qalys_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.504993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.629837</td>\n",
       "      <td>26.521638</td>\n",
       "      <td>0.501664</td>\n",
       "      <td>0.498336</td>\n",
       "      <td>26.896993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.695313</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.885192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.178164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.155406</td>\n",
       "      <td>90.810810</td>\n",
       "      <td>0.983108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147804</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.842780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.383916</td>\n",
       "      <td>90.691958</td>\n",
       "      <td>2.179909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138392</td>\n",
       "      <td>15.311533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>12.154066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.468551</td>\n",
       "      <td>0.531449</td>\n",
       "      <td>94.877571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>11.762335</td>\n",
       "      <td>90.881167</td>\n",
       "      <td>2.797582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.881320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.947280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.283180</td>\n",
       "      <td>56.054408</td>\n",
       "      <td>0.052720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.229829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.052111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.032724</td>\n",
       "      <td>20.225814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982630</td>\n",
       "      <td>14.447476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.941686</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.941686</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>67.938707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0    tax_increase  outlet_reduction  dec_smoking_prevalence  \\\n",
       "0       10.000000          0.000000                4.504993   \n",
       "1       10.000000         90.000000                7.000000   \n",
       "2       20.000000         95.000000                3.300000   \n",
       "3        9.155406         90.810810                0.983108   \n",
       "4       11.383916         90.691958                2.179909   \n",
       "..            ...               ...                     ...   \n",
       "369     10.000000         90.000000               12.154066   \n",
       "370     11.762335         90.881167                2.797582   \n",
       "371     10.000000          0.000000                1.947280   \n",
       "372     10.000000          0.000000                3.052111   \n",
       "373      0.000000          0.000000               13.941686   \n",
       "\n",
       "0    dec_tobacco_supply  dec_smoking_uptake  average_age  gender_idx  \\\n",
       "0                   0.0            9.629837    26.521638    0.501664   \n",
       "1                   0.0            0.000000     9.695313    1.000000   \n",
       "2                   0.0            0.000000    33.000000    0.000000   \n",
       "3                   0.0            0.147804    55.000000    0.000000   \n",
       "4                   0.0            0.000000    55.000000    0.000000   \n",
       "..                  ...                 ...          ...         ...   \n",
       "369                 0.0            0.000000    20.000000    0.468551   \n",
       "370                 0.0            0.000000    75.000000    0.000000   \n",
       "371                 0.0            3.283180    56.054408    0.052720   \n",
       "372                 0.0           14.032724    20.225814    0.000000   \n",
       "373               100.0            0.000000     9.941686    0.002666   \n",
       "\n",
       "0    ethnicity_idx   qalys_pc  \n",
       "0         0.498336  26.896993  \n",
       "1         1.000000  35.885192  \n",
       "2         1.000000  21.178164  \n",
       "3         1.000000   6.842780  \n",
       "4         0.138392  15.311533  \n",
       "..             ...        ...  \n",
       "369       0.531449  94.877571  \n",
       "370       0.000000   1.881320  \n",
       "371       0.000000  12.229829  \n",
       "372       0.982630  14.447476  \n",
       "373       0.773716  67.938707  \n",
       "\n",
       "[374 rows x 9 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to generate synthetic samples\n",
    "def generate_synthetic_samples(X, y, n_samples):\n",
    "    nn = NearestNeighbors(n_neighbors=5)\n",
    "    nn.fit(X)\n",
    "\n",
    "    synthetic_X = []\n",
    "    synthetic_y = []\n",
    "    for _ in range(n_samples):\n",
    "        idx = np.random.randint(0, len(X))\n",
    "        neighbors = nn.kneighbors([X[idx]], return_distance=False)[0]\n",
    "        \n",
    "        neighbor_idx = np.random.choice(neighbors)\n",
    "        lam = np.random.uniform(0, 1)\n",
    "        \n",
    "        # Generate synthetic sample using interpolation\n",
    "        new_sample_X = X[idx] + lam * (X[neighbor_idx] - X[idx])\n",
    "        new_sample_y = y[idx] + lam * (y[neighbor_idx] - y[idx])\n",
    "        \n",
    "        synthetic_X.append(new_sample_X)\n",
    "        synthetic_y.append(new_sample_y)\n",
    "    \n",
    "    return np.array(synthetic_X), np.array(synthetic_y)\n",
    "\n",
    "# Ensure that y is a 1D array for compatibility\n",
    "y_train_flat = y_train.values.flatten()\n",
    "\n",
    "# Generate synthetic samples\n",
    "X_train_res, y_train_res = generate_synthetic_samples(X_train.values, y_train_flat, n_samples=200)\n",
    "\n",
    "# Stack the original and synthetic data\n",
    "X_train_full = np.vstack([X_train.values, X_train_res])\n",
    "y_train_full = np.hstack([y_train_flat, y_train_res])\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df_resampled = pd.DataFrame(X_train_full, columns=X_train.columns)\n",
    "df_resampled['qalys_pc'] = y_train_full\n",
    "\n",
    "# Display the resampled dataframe\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "955f3cc8-ebda-4cfe-bbcd-417e604cc459",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_resampled[['tax_increase', 'outlet_reduction', 'dec_smoking_prevalence', \n",
    "              'dec_tobacco_supply', 'dec_smoking_uptake', 'average_age', \n",
    "              'gender_idx', 'ethnicity_idx']]\n",
    "y = df_resampled[['qalys_pc']]\n",
    "\n",
    "# Split the data into train and test sets (optional)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "112b498a-03a8-4fbe-abba-3e6d95ebd91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngjun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest (No Bootstrap): {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 200}\n",
      "Best MAPE for Random Forest (No Bootstrap): 0.19283427063816608\n",
      "Test MAPE for Random Forest (No Bootstrap): 0.22185960119448372\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestRegressor model with bootstrap disabled\n",
    "rf_model_no_bootstrap = RandomForestRegressor(random_state=42, bootstrap=False)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid_no_bootstrap = {\n",
    "    'n_estimators': [100, 200, 300],    # Number of trees in the forest\n",
    "    'max_depth': [3, 5, 10],            # Maximum depth of the tree\n",
    "    'min_samples_leaf': [1, 2, 4],      # Minimum number of samples required to be at a leaf node\n",
    "}\n",
    "\n",
    "# Define the MAPE scorer (using Mean Absolute Percentage Error)\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "# Setup GridSearchCV to perform cross-validation\n",
    "grid_search_rf_no_bootstrap = GridSearchCV(estimator=rf_model_no_bootstrap, param_grid=param_grid_no_bootstrap, \n",
    "                                           scoring=mape_scorer, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the duplicated training data\n",
    "grid_search_rf_no_bootstrap.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters from grid search\n",
    "print(\"Best Parameters for Random Forest (No Bootstrap):\", grid_search_rf_no_bootstrap.best_params_)\n",
    "\n",
    "# Best MAPE score from cross-validation\n",
    "print(\"Best MAPE for Random Forest (No Bootstrap):\", -grid_search_rf_no_bootstrap.best_score_)\n",
    "\n",
    "# Train a final model using the best parameters\n",
    "best_rf_model_no_bootstrap = grid_search_rf_no_bootstrap.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_rf_no_bootstrap = best_rf_model_no_bootstrap.predict(X_test)\n",
    "\n",
    "# Calculate the test MAPE\n",
    "test_mape_rf_no_bootstrap = mape(y_test, y_pred_rf_no_bootstrap)\n",
    "print(\"Test MAPE for Random Forest (No Bootstrap):\", test_mape_rf_no_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fee1349a-7bb1-4fc6-a759-4e923420a42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Parameters: {'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0.01, 'reg_lambda': 1}\n",
      "Best MAPE: 0.13512638298595708\n",
      "Test MAPE: 0.31217081811742936\n"
     ]
    }
   ],
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],   # Number of trees\n",
    "    'max_depth': [5, 10, 20],            # Depth of the trees\n",
    "    'min_child_weight': [1, 5, 10],     # Minimum sum of instance weight (hessian)\n",
    "    'reg_lambda': [0.01, 0.1, 1, 10],  # L2 regularization term (lambda)\n",
    "    'reg_alpha': [0.01, 0.1, 1, 10],      # L1 regularization term (alpha)\n",
    "}\n",
    "\n",
    "# Define the MAPE scorer (as we are optimizing based on Mean Absolute Percentage Error)\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "# Setup GridSearchCV to perform cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           scoring=mape_scorer, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the duplicated training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters from grid search\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best MAPE score from cross-validation\n",
    "print(\"Best MAPE:\", -grid_search.best_score_)\n",
    "\n",
    "# Train a final model using the best parameters\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate the test MAPE\n",
    "test_mape = mape(y_test, y_pred)\n",
    "print(\"Test MAPE:\", test_mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3eb4a76a-b119-4f20-aa02-584474799f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngjun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': 20, 'max_samples': 1.0, 'min_samples_leaf': 1, 'n_estimators': 300}\n",
      "Best MAPE for Random Forest: 0.2684251263913668\n",
      "Test MAPE for Random Forest: 0.29079338071442434\n"
     ]
    }
   ],
   "source": [
    "# Define the RandomForestRegressor model\n",
    "rf_model = RandomForestRegressor(random_state=42, bootstrap=True)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],    # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 20],            # Maximum depth of the tree\n",
    "    'min_samples_leaf': [1, 5, 10],      # Minimum number of samples required to be at a leaf node\n",
    "    'max_samples': [0.5, 0.7, 1.0],     # Maximum number of samples to draw from the data with replacement\n",
    "}\n",
    "\n",
    "# Define the MAPE scorer (using Mean Absolute Percentage Error)\n",
    "mape_scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "# Setup GridSearchCV to perform cross-validation\n",
    "grid_search_rf = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                              scoring=mape_scorer, cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the duplicated training data\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters from grid search\n",
    "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "\n",
    "# Best MAPE score from cross-validation\n",
    "print(\"Best MAPE for Random Forest:\", -grid_search_rf.best_score_)\n",
    "\n",
    "# Train a final model using the best parameters\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate the test MAPE\n",
    "test_mape_rf = mape(y_test, y_pred_rf)\n",
    "print(\"Test MAPE for Random Forest:\", test_mape_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cd061e-48f5-417e-9be6-682f3b6e84f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
